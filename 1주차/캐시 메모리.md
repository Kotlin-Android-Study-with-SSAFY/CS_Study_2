## 1. 캐시의 정의 및 필요성

- **캐시(Cache)**는 데이터나 값을 미리 저장하는 **임시 저장소**
- **주요 목적:**
  - **빠른 데이터 접근:** 자주 사용되거나 계산 비용이 큰 데이터를 미리 저장해 CPU가 빠르게 접근할 수 있도록 함.
  - **연산 비용 절감:** 반복 연산이나 느린 저장장치 접근을 줄여 전체 시스템 성능을 향상.
  - **속도 차이 극복:** 현대 CPU는 매우 빠르지만 메인 메모리(RAM)는 상대적으로 느리므로, 캐시를 통해 두 계층 간의 속도 격차를 줄임.


## 2. 캐시의 동작 원리와 지역성 (Locality)

![캐시 공간 지역성](https://github.com/user-attachments/assets/a1e4882d-535e-47ed-9bec-96a025d1bcc1)


- **지역성(Locality)의 원칙:**
  - **시간적 지역성 (Temporal Locality):** 한 번 사용된 데이터는 가까운 시점에 다시 사용될 가능성이 높음.
  - **공간적 지역성 (Spatial Locality):** 한 데이터 접근 시, 그 인접 데이터도 함께 사용될 가능성이 큼.
- 캐시는 불러온 데이터와 인접 데이터를 **캐시 라인 단위**로 저장하여 캐시 히트율을 높이고 캐시 미스를 줄임.


## 3. 캐시의 종류 및 메모리 계층 구조

![캐시 메모리 계층 구조](https://github.com/user-attachments/assets/0af250c8-de13-41df-ad31-8b65f878c05c)

- **메모리 계층 구조:**
  - **빠른 장치:** 레지스터, 캐시(L1, L2, L3) 등 — 용량은 작지만 매우 빠름.
  - **느린 장치:** DRAM, HDD, SSD 등 — 용량은 크지만 속도가 느림.
- **CPU 캐시:**
![캐시 메모리 위치](https://github.com/user-attachments/assets/e909b3cf-75d9-4aaf-a9a2-5525d5e35252)
  - **L1 캐시:** CPU 코어 내부, 가장 빠르지만 용량이 작음.
  - **L2 캐시:** L1보다 크고 느리며, 각 코어별 혹은 공유될 수 있음.
  - **L3 캐시:** 여러 코어가 공유하며, 가장 큰 용량이지만 상대적으로 느림.
- **캐시 위치:**
  - 로컬 캐시(특정 장비 내 사용)와 글로벌 캐시(여러 장비 간 공유)로 구분됨.


## 4. 캐시 매핑 방식

![캐시 매핑 방식](https://github.com/user-attachments/assets/e152c6e3-9046-4c10-b3b4-d8d4f3c9120a)


- **Direct Mapped Cache (직접 매핑 캐시):** 각 메모리 블록이 캐시의 특정 슬롯에만 저장되어 구조가 단순하지만 충돌 미스가 발생할 수 있음.
- **Fully Associative Cache (완전 연관 캐시):** 임의의 캐시 슬롯에 저장할 수 있어 충돌 미스가 적지만, 검색 시간이 길고 구현이 복잡함.
- **Set Associative Cache (집합 연관 캐시):** Direct Mapped와 Fully Associative의 절충안으로, 캐시를 여러 세트로 나누어 각 세트 내에서 저장 공간을 공유함.


## 5. 캐시 쓰기 정책 및 교체 알고리즘

- **쓰기 정책:**
  - **Write-Through:** 캐시에 기록할 때 메인 메모리에도 동시에 기록하여 일관성을 유지하지만 속도가 느림.
  - **Write-Back:** 캐시에만 기록한 후 나중에 메모리에 반영해 성능은 좋으나 추가적인 정합성 관리가 필요함.
- **캐시 교체 알고리즘:**

  - **FIFO (First In First Out):** 가장 먼저 저장된 데이터를 먼저 교체.
    ![FIFO](https://github.com/user-attachments/assets/acd1252f-9490-491a-b989-c7c11d341e79)


  - **LRU (Least Recently Used):** 가장 오랫동안 사용되지 않은 데이터를 교체.
    ![LRU](https://github.com/user-attachments/assets/c777f536-5282-4efb-a7c1-c3d639d8c292)


  - **LFU (Least Frequently Used):** 사용 빈도가 가장 낮은 데이터를 교체.
    ![LFU](https://github.com/user-attachments/assets/18d7a42d-8d66-4abc-bdcd-9a43fe0e5ecb)
    
  - **Random:** 임의로 선택하여 교체하는 방식.


## 6. 캐시 메모리와 가상 메모리의 차이점

- **캐시 메모리:**
  - CPU와 메인 메모리(RAM) 사이에 위치하여 데이터 접근 속도를 높이기 위한 고속 임시 저장소.
  - 용량이 작고 휘발성이며, **데이터의 지역성**에 기반해 효율성을 극대화함.
- **가상 메모리:**
  - 운영체제가 물리적 메모리의 한계를 극복하기 위해 사용하는 기술로, 디스크 공간을 확장된 메모리처럼 활용.
  - 비휘발성이며, 페이지 단위로 관리되어 데이터 접근 속도는 느리지만 큰 용량의 메모리를 사용할 수 있음.


## 7. 결론

- **캐시의 핵심 역할:** CPU와 메모리 간의 속도 차이를 줄이고, 자주 사용하는 데이터에 빠르게 접근하여 시스템 성능을 향상.
- **설계 포인트:** 캐시 매핑, 쓰기 정책, 교체 알고리즘 등은 캐시 효율성을 결정하는 중요한 요소.
- **시스템 병목 해소:** 적절한 캐시 설계를 통해 빠른 데이터 접근과 연산 비용 절감으로 컴퓨터 시스템의 병목 현상을 해소할 수 있음.

---

## [2018 1차 KAKAO BLIND RECRUITMENT] 캐시 문제

```java
import java.util.ArrayList;

public class Solution {
    public static int solution(int cacheSize, String[] cities) {
        int answer = 0;
        ArrayList<String> cache = new ArrayList<>();

        for (String city : cities) {
            city = city.toLowerCase();
            // cache hit
            if (cache.contains(city)) {
                answer++; // 실행시간 + 1
                cache.remove(city);
                cache.add(city); // 가장 최근에 사용된 캐시(후위로 옮김)
            }
            // cache miss
            else {
                answer += 5; // 실행시간 + 5
                if (cache.size() == cacheSize) {
                    if (cacheSize != 0) { // 캐시가 다 찬 경우: 교체
                        cache.remove(0);
                        cache.add(city);
                    }
                } else { // 캐시가 아직 차지 않은 경우
                    cache.add(city);
                }
            }
        }
        return answer;
    }
}
```
1. cities 배열을 순회
2. 도시 이름을 소문자로 바꿈
3. 캐시에 도시 이름이 있다면(hit) 실행시간 1 증가 후 도시를 삭제하고 캐시에 다시 넣음(최근에 실행되었다는 의미)
4. 캐시에 도시이름이 없고(miss), 캐시가 다 찬 경우 실행시간 5 증가 후 캐시의 첫번째 원소(가장 옛날에 실행됨)를 삭제하고 city를 추가
5. 캐시에 도시이름이 없고(miss), 캐시가 덜 찬 경우 실행시간 5 증가 후 city를 추가
